{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmaNagirireddi/ML_7/blob/main/ML7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmuzO6nhcCh8",
        "outputId": "93449e91-e823-4163-bb64-e04e9f239662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.12)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 240 µs (started: 2023-12-12 23:52:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, torch.nn as nn, torch.optim as optim, pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)\n",
        "np.random.seed(123)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIKWiM7NcsAy",
        "outputId": "c4c63699-f06d-42e4-dc82-2e55245a13dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.57 s (started: 2023-12-12 23:53:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwLS_AC0czfJ",
        "outputId": "02bb2f9d-8903-4ca8-c4a8-9cde9fb068f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 57.2 ms (started: 2023-12-12 23:53:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdgsPo2Mc9xQ",
        "outputId": "f3a97e02-e9fc-4ef8-ab0b-245c43e21e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 487 µs (started: 2023-12-12 23:54:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "mean, std = imgs.view(3, -1).mean(dim=1), imgs.view(3, -1).std(dim=1)\n",
        "mean, std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rmlvokFdBd6",
        "outputId": "3126fc8f-d19f-4d97-f48c-026a69173d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12813771.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "time: 27.7 s (started: 2023-12-12 23:56:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10('./data', train=True, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ir9J9xud4zJ",
        "outputId": "cf44b215-76e5-46e5-945b-0cc8ce4f4089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 502 ms (started: 2023-12-12 23:58:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_val = datasets.CIFAR10('./data', train=False, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szH1N8HkeGMn",
        "outputId": "bd587115-f9b8-4f22-c346-40942389889f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 376 ms (started: 2023-12-12 23:59:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = (DataLoader(ds, batch_size=32, shuffle=s, num_workers=2) for ds, s in ((cifar10, True), (cifar10_val, False)))\n",
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlVEg2UeeezO",
        "outputId": "9a255c4c-bde4-4e9d-8e50-2065686ef07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.05 ms (started: 2023-12-13 00:00:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 2 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNy2Ksmveo_0",
        "outputId": "5d585ffa-199d-45e4-cdc0-238b297ed478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 718 µs (started: 2023-12-13 00:01:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  # <1>\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1bkrqz8ewvD",
        "outputId": "9e29a66e-2c65-4e25-935d-926d34a644ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 647 µs (started: 2023-12-13 00:02:09 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class NetResDeep(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14tLk_lAfCFk",
        "outputId": "0e5b51cb-e194-488c-b53d-07b9e0abba46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 828 µs (started: 2023-12-13 00:03:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_n = NetResDeep(n_chans1=32, n_blocks=10).to(device=device)\n",
        "optimizer_n = optim.SGD(Model_n.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer_n,\n",
        "    model = Model_n,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCVFh5QrfMJ-",
        "outputId": "0027da8a-2429-4497-f329-1f680cebe6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-13 00:06:01.542054 Epoch 1, Training loss 1.672733060457885\n",
            "2023-12-13 00:06:18.609902 Epoch 2, Training loss 1.3218849350913395\n",
            "2023-12-13 00:06:52.164532 Epoch 4, Training loss 1.0942304098522213\n",
            "2023-12-13 00:07:25.282308 Epoch 6, Training loss 0.9790652731596775\n",
            "2023-12-13 00:07:59.566404 Epoch 8, Training loss 0.8980753872345749\n",
            "2023-12-13 00:08:33.005611 Epoch 10, Training loss 0.8390941984250769\n",
            "2023-12-13 00:09:06.558077 Epoch 12, Training loss 0.7891363979186755\n",
            "2023-12-13 00:09:40.708258 Epoch 14, Training loss 0.7482401559883711\n",
            "2023-12-13 00:10:14.187360 Epoch 16, Training loss 0.7153825359853963\n",
            "2023-12-13 00:10:47.388864 Epoch 18, Training loss 0.6806132789899048\n",
            "2023-12-13 00:11:22.498649 Epoch 20, Training loss 0.6513970437449518\n",
            "2023-12-13 00:11:56.814788 Epoch 22, Training loss 0.6244742403370558\n",
            "2023-12-13 00:12:30.262738 Epoch 24, Training loss 0.5968108157450316\n",
            "2023-12-13 00:13:04.614420 Epoch 26, Training loss 0.5738908010210201\n",
            "2023-12-13 00:13:38.807137 Epoch 28, Training loss 0.5491022150713285\n",
            "2023-12-13 00:14:13.592391 Epoch 30, Training loss 0.5286458699045773\n",
            "2023-12-13 00:14:48.205786 Epoch 32, Training loss 0.5030821176318503\n",
            "2023-12-13 00:15:22.928136 Epoch 34, Training loss 0.48633431039288194\n",
            "2023-12-13 00:15:57.300493 Epoch 36, Training loss 0.46385529770808426\n",
            "2023-12-13 00:16:30.419755 Epoch 38, Training loss 0.4477113628294021\n",
            "2023-12-13 00:17:05.128352 Epoch 40, Training loss 0.4285415007672627\n",
            "2023-12-13 00:17:38.574977 Epoch 42, Training loss 0.4116193527261645\n",
            "2023-12-13 00:18:13.282567 Epoch 44, Training loss 0.3937643065057118\n",
            "2023-12-13 00:18:47.901234 Epoch 46, Training loss 0.37188979274499745\n",
            "2023-12-13 00:19:22.116440 Epoch 48, Training loss 0.3565910098572534\n",
            "2023-12-13 00:19:56.214355 Epoch 50, Training loss 0.3450022762830793\n",
            "2023-12-13 00:20:29.608473 Epoch 52, Training loss 0.3237538918118712\n",
            "2023-12-13 00:21:03.876421 Epoch 54, Training loss 0.31409268724712436\n",
            "2023-12-13 00:21:38.247006 Epoch 56, Training loss 0.29985838300135564\n",
            "2023-12-13 00:22:12.829863 Epoch 58, Training loss 0.2885974236202122\n",
            "2023-12-13 00:22:47.586005 Epoch 60, Training loss 0.2687765126231574\n",
            "2023-12-13 00:23:22.888129 Epoch 62, Training loss 0.2598361055690245\n",
            "2023-12-13 00:23:58.568254 Epoch 64, Training loss 0.25022784457854824\n",
            "2023-12-13 00:24:33.547970 Epoch 66, Training loss 0.2396629535565087\n",
            "2023-12-13 00:25:07.224331 Epoch 68, Training loss 0.2253059135143355\n",
            "2023-12-13 00:25:41.813984 Epoch 70, Training loss 0.22156728581738105\n",
            "2023-12-13 00:26:15.985150 Epoch 72, Training loss 0.20764109995740485\n",
            "2023-12-13 00:26:50.595230 Epoch 74, Training loss 0.20057842724254057\n",
            "2023-12-13 00:27:24.374313 Epoch 76, Training loss 0.19024988924649497\n",
            "2023-12-13 00:27:59.590694 Epoch 78, Training loss 0.18898875559534178\n",
            "2023-12-13 00:28:35.263157 Epoch 80, Training loss 0.17990189836368262\n",
            "2023-12-13 00:29:09.454410 Epoch 82, Training loss 0.1760038197164496\n",
            "2023-12-13 00:29:42.826676 Epoch 84, Training loss 0.156162248621084\n",
            "2023-12-13 00:30:16.256008 Epoch 86, Training loss 0.16523659995608675\n",
            "2023-12-13 00:30:50.090688 Epoch 88, Training loss 0.15024719422031255\n",
            "2023-12-13 00:31:25.223094 Epoch 90, Training loss 0.13841147975840024\n",
            "2023-12-13 00:32:00.793111 Epoch 92, Training loss 0.14362896504598627\n",
            "2023-12-13 00:32:35.053175 Epoch 94, Training loss 0.13686752646505446\n",
            "2023-12-13 00:33:10.072202 Epoch 96, Training loss 0.12482906674450205\n",
            "2023-12-13 00:33:44.516047 Epoch 98, Training loss 0.12833821695531533\n",
            "2023-12-13 00:34:18.801779 Epoch 100, Training loss 0.12795907401277787\n",
            "2023-12-13 00:34:53.974822 Epoch 102, Training loss 0.11437077175644694\n",
            "2023-12-13 00:35:29.452662 Epoch 104, Training loss 0.12172476898075003\n",
            "2023-12-13 00:36:04.566466 Epoch 106, Training loss 0.10405033555087977\n",
            "2023-12-13 00:36:39.742680 Epoch 108, Training loss 0.1096697442372248\n",
            "2023-12-13 00:37:13.682723 Epoch 110, Training loss 0.10162307299814775\n",
            "2023-12-13 00:37:49.159276 Epoch 112, Training loss 0.11072731167968823\n",
            "2023-12-13 00:38:23.162977 Epoch 114, Training loss 0.09273404779415566\n",
            "2023-12-13 00:38:57.479147 Epoch 116, Training loss 0.08781242326452555\n",
            "2023-12-13 00:39:32.111512 Epoch 118, Training loss 0.09807162681901059\n",
            "2023-12-13 00:40:06.399803 Epoch 120, Training loss 0.09756409765849211\n",
            "2023-12-13 00:40:40.258792 Epoch 122, Training loss 0.08967848540861273\n",
            "2023-12-13 00:41:14.244965 Epoch 124, Training loss 0.0825948056726021\n",
            "2023-12-13 00:41:48.477103 Epoch 126, Training loss 0.08603272715192264\n",
            "2023-12-13 00:42:21.596022 Epoch 128, Training loss 0.07775063696175859\n",
            "2023-12-13 00:42:55.666901 Epoch 130, Training loss 0.06930421351481071\n",
            "2023-12-13 00:43:29.607983 Epoch 132, Training loss 0.08901142251058271\n",
            "2023-12-13 00:44:03.954618 Epoch 134, Training loss 0.0755275165176845\n",
            "2023-12-13 00:44:40.078014 Epoch 136, Training loss 0.07120204220163343\n",
            "2023-12-13 00:45:14.770444 Epoch 138, Training loss 0.08184701396091004\n",
            "2023-12-13 00:45:49.807123 Epoch 140, Training loss 0.07752554842341072\n",
            "2023-12-13 00:46:23.663464 Epoch 142, Training loss 0.07395491567863388\n",
            "2023-12-13 00:46:57.055682 Epoch 144, Training loss 0.05777116961489263\n",
            "2023-12-13 00:47:31.778515 Epoch 146, Training loss 0.0657127276826778\n",
            "2023-12-13 00:48:06.986915 Epoch 148, Training loss 0.05568737786957995\n",
            "2023-12-13 00:48:40.352088 Epoch 150, Training loss 0.061217759412705006\n",
            "2023-12-13 00:49:14.165100 Epoch 152, Training loss 0.04960150745594088\n",
            "2023-12-13 00:49:48.582664 Epoch 154, Training loss 0.04987816029464825\n",
            "2023-12-13 00:50:22.531053 Epoch 156, Training loss 0.07033703776954355\n",
            "2023-12-13 00:50:56.568290 Epoch 158, Training loss 0.07375611867805182\n",
            "2023-12-13 00:51:30.391550 Epoch 160, Training loss 0.065837314771317\n",
            "2023-12-13 00:52:04.855078 Epoch 162, Training loss 0.0523012366621938\n",
            "2023-12-13 00:52:39.133318 Epoch 164, Training loss 0.05471711051762441\n",
            "2023-12-13 00:53:13.567809 Epoch 166, Training loss 0.06259281100679272\n",
            "2023-12-13 00:53:47.415157 Epoch 168, Training loss 0.052962130010281085\n",
            "2023-12-13 00:54:21.000133 Epoch 170, Training loss 0.05107521966390554\n",
            "2023-12-13 00:54:54.193049 Epoch 172, Training loss 0.05899437272264218\n",
            "2023-12-13 00:55:28.120426 Epoch 174, Training loss 0.05388997536389007\n",
            "2023-12-13 00:56:02.529239 Epoch 176, Training loss 0.04402891289577143\n",
            "2023-12-13 00:56:36.287362 Epoch 178, Training loss 0.04728578393270771\n",
            "2023-12-13 00:57:10.084977 Epoch 180, Training loss 0.05283252431777418\n",
            "2023-12-13 00:57:43.968120 Epoch 182, Training loss 0.04619618853010243\n",
            "2023-12-13 00:58:18.351758 Epoch 184, Training loss 0.042713794385746136\n",
            "2023-12-13 00:58:52.557113 Epoch 186, Training loss 0.038900099922746095\n",
            "2023-12-13 00:59:27.098566 Epoch 188, Training loss 0.03989738875087773\n",
            "2023-12-13 01:00:01.198467 Epoch 190, Training loss 0.03537117180120797\n",
            "2023-12-13 01:00:35.227141 Epoch 192, Training loss 0.0461208381560086\n",
            "2023-12-13 01:01:08.591544 Epoch 194, Training loss 0.05505935435148675\n",
            "2023-12-13 01:01:41.963835 Epoch 196, Training loss 0.04202765876293356\n",
            "2023-12-13 01:02:15.730628 Epoch 198, Training loss 0.04567748763076681\n",
            "2023-12-13 01:02:49.809178 Epoch 200, Training loss 0.0499809440922514\n",
            "2023-12-13 01:03:23.508862 Epoch 202, Training loss 0.04328838412401383\n",
            "2023-12-13 01:03:57.736087 Epoch 204, Training loss 0.045842349095083015\n",
            "2023-12-13 01:04:31.102491 Epoch 206, Training loss 0.0464049168236037\n",
            "2023-12-13 01:05:04.579902 Epoch 208, Training loss 0.03535480335503276\n",
            "2023-12-13 01:05:39.814384 Epoch 210, Training loss 0.027982372198871622\n",
            "2023-12-13 01:06:13.174041 Epoch 212, Training loss 0.035351128265231783\n",
            "2023-12-13 01:06:47.149280 Epoch 214, Training loss 0.030402564943142585\n",
            "2023-12-13 01:07:21.987471 Epoch 216, Training loss 0.028143335520087062\n",
            "2023-12-13 01:07:55.970315 Epoch 218, Training loss 0.028674365902945458\n",
            "2023-12-13 01:08:29.445152 Epoch 220, Training loss 0.02683328214402056\n",
            "2023-12-13 01:09:03.595891 Epoch 222, Training loss 0.019168056659467126\n",
            "2023-12-13 01:09:37.130463 Epoch 224, Training loss 0.04237662391111948\n",
            "2023-12-13 01:10:11.271961 Epoch 226, Training loss 0.035599020804921035\n",
            "2023-12-13 01:10:44.348723 Epoch 228, Training loss 0.034773521746512555\n",
            "2023-12-13 01:11:18.330058 Epoch 230, Training loss 0.04101005828654689\n",
            "2023-12-13 01:11:52.037039 Epoch 232, Training loss 0.03480754797131265\n",
            "2023-12-13 01:12:26.894602 Epoch 234, Training loss 0.02549927059270311\n",
            "2023-12-13 01:13:00.898507 Epoch 236, Training loss 0.04100467662465118\n",
            "2023-12-13 01:13:35.252067 Epoch 238, Training loss 0.024501290250525935\n",
            "2023-12-13 01:14:10.243567 Epoch 240, Training loss 0.029171346134578096\n",
            "2023-12-13 01:14:43.866799 Epoch 242, Training loss 0.036659657313235165\n",
            "2023-12-13 01:15:17.344544 Epoch 244, Training loss 0.04939762650712244\n",
            "2023-12-13 01:15:51.233086 Epoch 246, Training loss 0.04157568025330803\n",
            "2023-12-13 01:16:25.250248 Epoch 248, Training loss 0.031957451164052776\n",
            "2023-12-13 01:16:59.467212 Epoch 250, Training loss 0.04928982615796158\n",
            "2023-12-13 01:17:33.047206 Epoch 252, Training loss 0.030482466435951174\n",
            "2023-12-13 01:18:06.876416 Epoch 254, Training loss 0.043663511461677365\n",
            "2023-12-13 01:18:40.559800 Epoch 256, Training loss 0.03859472319777393\n",
            "2023-12-13 01:19:14.616829 Epoch 258, Training loss 0.03235929969932008\n",
            "2023-12-13 01:19:47.902359 Epoch 260, Training loss 0.025788387863168855\n",
            "2023-12-13 01:20:21.746494 Epoch 262, Training loss 0.02475317123394109\n",
            "2023-12-13 01:20:56.446916 Epoch 264, Training loss 0.01649627055263043\n",
            "2023-12-13 01:21:30.318970 Epoch 266, Training loss 0.01622009275774857\n",
            "2023-12-13 01:22:04.001221 Epoch 268, Training loss 0.014193072239878934\n",
            "2023-12-13 01:22:40.161658 Epoch 270, Training loss 0.014803533267029774\n",
            "2023-12-13 01:23:14.078288 Epoch 272, Training loss 0.015777201835434\n",
            "2023-12-13 01:23:48.093644 Epoch 274, Training loss 0.02628894528106597\n",
            "2023-12-13 01:24:22.395698 Epoch 276, Training loss 0.014312276438749294\n",
            "2023-12-13 01:24:56.348423 Epoch 278, Training loss 0.01917452532354209\n",
            "2023-12-13 01:25:30.684254 Epoch 280, Training loss 0.021507593773092668\n",
            "2023-12-13 01:26:04.472183 Epoch 282, Training loss 0.043704862501095544\n",
            "2023-12-13 01:26:38.048813 Epoch 284, Training loss 0.034062385575514616\n",
            "2023-12-13 01:27:13.377490 Epoch 286, Training loss 0.032125954696594766\n",
            "2023-12-13 01:27:46.910198 Epoch 288, Training loss 0.026943932971747867\n",
            "2023-12-13 01:28:21.251412 Epoch 290, Training loss 0.03389650537328128\n",
            "2023-12-13 01:28:56.734628 Epoch 292, Training loss 0.019763186448515612\n",
            "2023-12-13 01:29:30.622870 Epoch 294, Training loss 0.023301762604977166\n",
            "2023-12-13 01:30:04.931913 Epoch 296, Training loss 0.01942941535580013\n",
            "2023-12-13 01:30:38.981966 Epoch 298, Training loss 0.013681429070409647\n",
            "2023-12-13 01:31:13.514764 Epoch 300, Training loss 0.01692733711767355\n",
            "time: 1h 25min 29s (started: 2023-12-13 00:05:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "valLoader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "def validate(model, trainLoader, valLoader):\n",
        "    accdict = {}\n",
        "    predictions = []\n",
        "    exp_labels = []\n",
        "\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", valLoader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "                exp_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict, predictions, exp_labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU2goHl7gvhQ",
        "outputId": "267b6dc8-7777-4ded-b099-2041a86a4997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.24 ms (started: 2023-12-13 01:38:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_n, predictions_n, expectedLabels = validate(Model_n, trainLoader, valLoader)\n",
        "precision_n, recall_n, cnfMatrix = precision_score(predictions_n, expectedLabels, average='macro'), recall_score(predictions_n, expectedLabels, average='macro'), confusion_matrix(predictions_n, expectedLabels)\n",
        "print(cnfMatrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Uoq9MZhJn7",
        "outputId": "41b86e01-a54f-4114-adba-754ff1351609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 1.00\n",
            "Accuracy val: 0.66\n",
            "[[5638   30   73   27   25   17    3   15  100   41]\n",
            " [  29 5786   10   21    8    5    6   10   52   98]\n",
            " [  98   10 5521   71  110   64   65   43   25   15]\n",
            " [  28    9   73 5444   69  166   64   39   21   16]\n",
            " [  22    4   90   71 5504   41   48   49   12    9]\n",
            " [  16    7   75  191   69 5559   36   71   13   10]\n",
            " [  15   11   74   76   67   36 5743    9   10   11]\n",
            " [  23    4   65   67  127   89   19 5745   10   19]\n",
            " [  77   33    8   16   15   12    8    3 5722   27]\n",
            " [  54  106   11   16    6   11    8   16   35 5754]]\n",
            "time: 11.5 s (started: 2023-12-13 01:38:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions_n, expectedLabels, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTCI6I0xhpus",
        "outputId": "d1327757-6ff0-48e4-e132-da301d2302ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.94      0.94      0.94      5969\n",
            "  automobile       0.96      0.96      0.96      6025\n",
            "        bird       0.92      0.92      0.92      6022\n",
            "         cat       0.91      0.92      0.91      5929\n",
            "        deer       0.92      0.94      0.93      5850\n",
            "         dog       0.93      0.92      0.92      6047\n",
            "        frog       0.96      0.95      0.95      6052\n",
            "       horse       0.96      0.93      0.94      6168\n",
            "        ship       0.95      0.97      0.96      5921\n",
            "       truck       0.96      0.96      0.96      6017\n",
            "\n",
            "    accuracy                           0.94     60000\n",
            "   macro avg       0.94      0.94      0.94     60000\n",
            "weighted avg       0.94      0.94      0.94     60000\n",
            "\n",
            "time: 143 ms (started: 2023-12-13 01:39:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NetWidth(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qHEOf8-ir6O",
        "outputId": "e5030aa8-7eda-4367-8b2c-10a0507b830c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 782 µs (started: 2023-12-13 01:39:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn,\n",
        "                        train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            l2_lambda = 0.001\n",
        "            l2_norm = sum(p.pow(2.0).sum()\n",
        "                          for p in model.parameters())  # <1>\n",
        "            loss = loss + l2_lambda * l2_norm\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OQvDp8_itKZ",
        "outputId": "f1daba59-8e5e-42ca-b622-f522e0bd048d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 679 µs (started: 2023-12-13 01:39:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelWd = NetWidth(n_chans1=32).to(device=device)\n",
        "training_loop_l2reg(300, optim.SGD(modelWd.parameters(), lr=1e-2), modelWd, nn.CrossEntropyLoss(), trainLoader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c4C0KqHjF9P",
        "outputId": "d26b7112-f46c-454f-dfbf-540341ba9d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-13 01:39:15.408756 Epoch 1, Training loss 1.9960977820789112\n",
            "2023-12-13 01:41:30.030288 Epoch 10, Training loss 1.1806000449011087\n",
            "2023-12-13 01:43:59.481680 Epoch 20, Training loss 0.9877848781435691\n",
            "2023-12-13 01:46:29.565967 Epoch 30, Training loss 0.9088765910976683\n",
            "2023-12-13 01:48:59.064253 Epoch 40, Training loss 0.8647717310644477\n",
            "2023-12-13 01:51:27.926125 Epoch 50, Training loss 0.8352194234080936\n",
            "2023-12-13 01:53:56.840882 Epoch 60, Training loss 0.8138626804742057\n",
            "2023-12-13 01:56:26.624072 Epoch 70, Training loss 0.7976617735365162\n",
            "2023-12-13 01:58:56.414703 Epoch 80, Training loss 0.7849743370052493\n",
            "2023-12-13 02:01:26.380860 Epoch 90, Training loss 0.7748633558335511\n",
            "2023-12-13 02:03:56.590332 Epoch 100, Training loss 0.7665573676376392\n",
            "2023-12-13 02:06:26.407034 Epoch 110, Training loss 0.759614470517239\n",
            "2023-12-13 02:08:55.635963 Epoch 120, Training loss 0.7537946329854638\n",
            "2023-12-13 02:11:25.725706 Epoch 130, Training loss 0.7488175724321009\n",
            "2023-12-13 02:13:56.418402 Epoch 140, Training loss 0.7445739150199744\n",
            "2023-12-13 02:16:26.684577 Epoch 150, Training loss 0.740952424457311\n",
            "2023-12-13 02:18:57.030772 Epoch 160, Training loss 0.7378040606256031\n",
            "2023-12-13 02:21:26.823026 Epoch 170, Training loss 0.7350440950649778\n",
            "2023-12-13 02:23:56.694742 Epoch 180, Training loss 0.7326021547360189\n",
            "2023-12-13 02:26:26.167865 Epoch 190, Training loss 0.7304765695653608\n",
            "2023-12-13 02:28:56.151637 Epoch 200, Training loss 0.7285921358696336\n",
            "2023-12-13 02:31:26.675809 Epoch 210, Training loss 0.7269282841773899\n",
            "2023-12-13 02:33:56.784311 Epoch 220, Training loss 0.7253948761069257\n",
            "2023-12-13 02:36:27.153140 Epoch 230, Training loss 0.7240348385880365\n",
            "2023-12-13 02:38:57.306945 Epoch 240, Training loss 0.722778797225879\n",
            "2023-12-13 02:41:27.818506 Epoch 250, Training loss 0.721628332381968\n",
            "2023-12-13 02:43:58.105413 Epoch 260, Training loss 0.7205083060752401\n",
            "2023-12-13 02:46:28.150353 Epoch 270, Training loss 0.7195029471383985\n",
            "2023-12-13 02:48:57.835839 Epoch 280, Training loss 0.7185290945155541\n",
            "2023-12-13 02:51:27.964219 Epoch 290, Training loss 0.7176064061539252\n",
            "2023-12-13 02:53:58.257495 Epoch 300, Training loss 0.7167052335446448\n",
            "time: 1h 14min 57s (started: 2023-12-13 01:39:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyWd, predictionsWd, expectedLabelsWd = validate(modelWd, trainLoader, valLoader)\n",
        "precisionWd, recallWd = (precision_score(predictionsWd, expectedLabelsWd, average='macro'),\n",
        "                         recall_score(predictionsWd, expectedLabelsWd, average='macro'))\n",
        "cnfMatrixWd = confusion_matrix(predictionsWd, expectedLabelsWd)\n",
        "print(cnfMatrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPuHDELpjdIk",
        "outputId": "d392f64a-94ff-4a05-bc49-94f3a2da3a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.87\n",
            "Accuracy val: 0.69\n",
            "[[5638   30   73   27   25   17    3   15  100   41]\n",
            " [  29 5786   10   21    8    5    6   10   52   98]\n",
            " [  98   10 5521   71  110   64   65   43   25   15]\n",
            " [  28    9   73 5444   69  166   64   39   21   16]\n",
            " [  22    4   90   71 5504   41   48   49   12    9]\n",
            " [  16    7   75  191   69 5559   36   71   13   10]\n",
            " [  15   11   74   76   67   36 5743    9   10   11]\n",
            " [  23    4   65   67  127   89   19 5745   10   19]\n",
            " [  77   33    8   16   15   12    8    3 5722   27]\n",
            " [  54  106   11   16    6   11    8   16   35 5754]]\n",
            "time: 10.4 s (started: 2023-12-13 02:53:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictionsWd, expectedLabelsWd, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtBx_FtWj6XI",
        "outputId": "b1ebe825-3129-431d-ec2f-a2a7dd81e969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.83      0.86      0.84      5778\n",
            "  automobile       0.92      0.92      0.92      5994\n",
            "        bird       0.77      0.76      0.76      6058\n",
            "         cat       0.75      0.71      0.73      6404\n",
            "        deer       0.79      0.81      0.80      5845\n",
            "         dog       0.80      0.76      0.78      6306\n",
            "        frog       0.88      0.86      0.87      6166\n",
            "       horse       0.86      0.86      0.86      5996\n",
            "        ship       0.87      0.92      0.89      5674\n",
            "       truck       0.89      0.92      0.90      5779\n",
            "\n",
            "    accuracy                           0.84     60000\n",
            "   macro avg       0.84      0.84      0.84     60000\n",
            "weighted avg       0.84      0.84      0.84     60000\n",
            "\n",
            "time: 144 ms (started: 2023-12-13 02:54:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NetDropout(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv2_dropout = nn.Dropout2d(p=0.3)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = self.conv1_dropout(out)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = self.conv2_dropout(out)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11xnJCmPkURx",
        "outputId": "79bbe8bb-9b8b-41bc-c8f6-299340752c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 806 µs (started: 2023-12-13 02:54:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelDropout = NetDropout(n_chans1=32).to(device)\n",
        "training_loop(100, optim.SGD(modelDropout.parameters(), lr=1e-2), modelDropout, nn.CrossEntropyLoss(), trainLoader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m9YYMgzGI4G",
        "outputId": "aa7a9954-a112-45f2-f9ce-cc9811a5326d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-13 02:54:28.806272 Epoch 1, Training loss 2.010632708706819\n",
            "2023-12-13 02:54:42.951110 Epoch 2, Training loss 1.7617251638256375\n",
            "2023-12-13 02:55:10.934620 Epoch 4, Training loss 1.5603083641937627\n",
            "2023-12-13 02:55:38.843249 Epoch 6, Training loss 1.4585976015271434\n",
            "2023-12-13 02:56:06.865842 Epoch 8, Training loss 1.3876442375695308\n",
            "2023-12-13 02:56:34.822441 Epoch 10, Training loss 1.3370900048929102\n",
            "2023-12-13 02:57:02.818491 Epoch 12, Training loss 1.2908255769621075\n",
            "2023-12-13 02:57:30.767301 Epoch 14, Training loss 1.260003665066741\n",
            "2023-12-13 02:57:58.780888 Epoch 16, Training loss 1.2269336489003029\n",
            "2023-12-13 02:58:26.729799 Epoch 18, Training loss 1.1982291987942308\n",
            "2023-12-13 02:58:54.620025 Epoch 20, Training loss 1.175606329270336\n",
            "2023-12-13 02:59:22.839701 Epoch 22, Training loss 1.1502697816895098\n",
            "2023-12-13 02:59:51.016604 Epoch 24, Training loss 1.1386213134926604\n",
            "2023-12-13 03:00:19.286723 Epoch 26, Training loss 1.1216915629403976\n",
            "2023-12-13 03:00:47.198654 Epoch 28, Training loss 1.1065464526643534\n",
            "2023-12-13 03:01:15.198311 Epoch 30, Training loss 1.0948363436609887\n",
            "2023-12-13 03:01:43.222868 Epoch 32, Training loss 1.0868317874343805\n",
            "2023-12-13 03:02:11.252917 Epoch 34, Training loss 1.073433175035145\n",
            "2023-12-13 03:02:39.344987 Epoch 36, Training loss 1.0718196015376265\n",
            "2023-12-13 03:03:07.624760 Epoch 38, Training loss 1.0629290227237564\n",
            "2023-12-13 03:03:35.844949 Epoch 40, Training loss 1.0492227604931883\n",
            "2023-12-13 03:04:04.001692 Epoch 42, Training loss 1.050590672151512\n",
            "2023-12-13 03:04:32.172407 Epoch 44, Training loss 1.0376691831957043\n",
            "2023-12-13 03:05:00.355974 Epoch 46, Training loss 1.0410544313585666\n",
            "2023-12-13 03:05:28.696855 Epoch 48, Training loss 1.0285271672946412\n",
            "2023-12-13 03:05:56.968383 Epoch 50, Training loss 1.0233033928267485\n",
            "2023-12-13 03:06:25.101644 Epoch 52, Training loss 1.015128624484972\n",
            "2023-12-13 03:06:53.102700 Epoch 54, Training loss 1.0213930935353575\n",
            "2023-12-13 03:07:21.121385 Epoch 56, Training loss 1.0062549850519966\n",
            "2023-12-13 03:07:49.193211 Epoch 58, Training loss 1.0083070324205072\n",
            "2023-12-13 03:08:17.316035 Epoch 60, Training loss 1.004591733979447\n",
            "2023-12-13 03:08:45.485227 Epoch 62, Training loss 1.00117377635768\n",
            "2023-12-13 03:09:13.520817 Epoch 64, Training loss 0.9931694556532613\n",
            "2023-12-13 03:09:41.648541 Epoch 66, Training loss 0.9920357966514499\n",
            "2023-12-13 03:10:09.729849 Epoch 68, Training loss 0.9840625558820222\n",
            "2023-12-13 03:10:37.791855 Epoch 70, Training loss 0.981764770224881\n",
            "2023-12-13 03:11:05.920791 Epoch 72, Training loss 0.9771561108129408\n",
            "2023-12-13 03:11:34.094419 Epoch 74, Training loss 0.9802757813345135\n",
            "2023-12-13 03:12:02.245733 Epoch 76, Training loss 0.9737747996816855\n",
            "2023-12-13 03:12:30.370927 Epoch 78, Training loss 0.9696411063604038\n",
            "2023-12-13 03:12:58.655004 Epoch 80, Training loss 0.96823683221017\n",
            "2023-12-13 03:13:27.177032 Epoch 82, Training loss 0.9704588727877878\n",
            "2023-12-13 03:13:55.232171 Epoch 84, Training loss 0.9663177311725324\n",
            "2023-12-13 03:14:23.152482 Epoch 86, Training loss 0.9595924141004567\n",
            "2023-12-13 03:14:51.100031 Epoch 88, Training loss 0.9604520995141296\n",
            "2023-12-13 03:15:19.116941 Epoch 90, Training loss 0.955006845657478\n",
            "2023-12-13 03:15:47.284746 Epoch 92, Training loss 0.9526190474972396\n",
            "2023-12-13 03:16:15.297242 Epoch 94, Training loss 0.9500890132563803\n",
            "2023-12-13 03:16:43.437027 Epoch 96, Training loss 0.9500015259093946\n",
            "2023-12-13 03:17:11.548138 Epoch 98, Training loss 0.9505281955994609\n",
            "2023-12-13 03:17:39.579902 Epoch 100, Training loss 0.9393069997925283\n",
            "time: 23min 24s (started: 2023-12-13 02:54:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyDropout, predictionsDropout, expectedLabelsDropout = validate(modelDropout, trainLoader, valLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1kZGKh8kB0n",
        "outputId": "ef9be000-ae2d-4633-c3f2-f1cf19d8cacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.67\n",
            "Accuracy val: 0.61\n",
            "time: 9.98 s (started: 2023-12-13 03:17:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisionDropout = precision_score(predictionsDropout, expectedLabelsDropout, average='macro')\n",
        "recallDropout = recall_score(predictionsDropout, expectedLabelsDropout, average='macro')\n",
        "cnfMatrixDropout = confusion_matrix(predictionsDropout, expectedLabelsDropout)\n",
        "print(cnfMatrixDropout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrgLu2Zpkrun",
        "outputId": "587c7e8a-97db-46ea-9915-63530c88088d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4295  155  424  125  189   54   52   75  600  219]\n",
            " [ 153 4601   41   67   38   44   46   43  273  595]\n",
            " [ 317   58 3184  390  522  426  228  221  100   55]\n",
            " [ 179   90  387 2938  400 1159  402  355  131  131]\n",
            " [ 108   44  694  417 3575  423  328  459   54   45]\n",
            " [  66   32  334  887  214 3047  118  346   31   43]\n",
            " [  61   91  540  710  541  344 4681  123   64  100]\n",
            " [ 107   54  224  256  406  378   56 4176   48  143]\n",
            " [ 431  198  103  100   59   54   40   49 4436  156]\n",
            " [ 283  677   69  110   56   71   49  153  263 4513]]\n",
            "time: 166 ms (started: 2023-12-13 03:17:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictionsDropout, expectedLabelsDropout, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qFb5J5olalf",
        "outputId": "37d8676b-cf38-4275-9fec-6ab1f59b61cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.72      0.69      0.70      6188\n",
            "  automobile       0.77      0.78      0.77      5901\n",
            "        bird       0.53      0.58      0.55      5501\n",
            "         cat       0.49      0.48      0.48      6172\n",
            "        deer       0.60      0.58      0.59      6147\n",
            "         dog       0.51      0.60      0.55      5118\n",
            "        frog       0.78      0.65      0.71      7255\n",
            "       horse       0.70      0.71      0.70      5848\n",
            "        ship       0.74      0.79      0.76      5626\n",
            "       truck       0.75      0.72      0.74      6244\n",
            "\n",
            "    accuracy                           0.66     60000\n",
            "   macro avg       0.66      0.66      0.66     60000\n",
            "weighted avg       0.66      0.66      0.66     60000\n",
            "\n",
            "time: 145 ms (started: 2023-12-13 03:17:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NetBatchNorm(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1_batchnorm(self.conv1(x))\n",
        "        out = F.max_pool2d(torch.tanh(out), 2)\n",
        "        out = self.conv2_batchnorm(self.conv2(out))\n",
        "        out = F.max_pool2d(torch.tanh(out), 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYC0IBOmlsd0",
        "outputId": "d078d2e2-8350-465f-d714-16fbd5bf7545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 852 µs (started: 2023-12-13 03:17:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBatchNorm = NetBatchNorm(n_chans1=32).to(device=device)\n",
        "optimizerBatchNorm = optim.SGD(modelBatchNorm.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizerBatchNorm,\n",
        "    model = modelBatchNorm,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tnJ4Nbmlx12",
        "outputId": "c6cb9ca6-592c-4748-da49-a2cfcc48a2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-13 03:17:57.635948 Epoch 1, Training loss 1.6479532561924544\n",
            "2023-12-13 03:18:05.239507 Epoch 2, Training loss 1.321204065018103\n",
            "2023-12-13 03:18:20.174032 Epoch 4, Training loss 1.0985896263226285\n",
            "2023-12-13 03:18:35.154568 Epoch 6, Training loss 0.9815801281770375\n",
            "2023-12-13 03:18:50.328404 Epoch 8, Training loss 0.9080408466640223\n",
            "2023-12-13 03:19:05.068961 Epoch 10, Training loss 0.8561229745470708\n",
            "2023-12-13 03:19:20.264188 Epoch 12, Training loss 0.8144746814221049\n",
            "2023-12-13 03:19:35.246354 Epoch 14, Training loss 0.7799158152371588\n",
            "2023-12-13 03:19:50.625667 Epoch 16, Training loss 0.7530139590484243\n",
            "2023-12-13 03:20:05.781374 Epoch 18, Training loss 0.7254330565818059\n",
            "2023-12-13 03:20:21.327853 Epoch 20, Training loss 0.701974105163789\n",
            "2023-12-13 03:20:36.509911 Epoch 22, Training loss 0.6819875512417508\n",
            "2023-12-13 03:20:51.586974 Epoch 24, Training loss 0.662671828529275\n",
            "2023-12-13 03:21:06.589860 Epoch 26, Training loss 0.6426331825883284\n",
            "2023-12-13 03:21:21.965637 Epoch 28, Training loss 0.6261871274053021\n",
            "2023-12-13 03:21:37.006572 Epoch 30, Training loss 0.6069280037457411\n",
            "2023-12-13 03:21:52.170241 Epoch 32, Training loss 0.5937626526303117\n",
            "2023-12-13 03:22:07.115462 Epoch 34, Training loss 0.5790857068541259\n",
            "2023-12-13 03:22:22.302693 Epoch 36, Training loss 0.565052878061549\n",
            "2023-12-13 03:22:37.366073 Epoch 38, Training loss 0.549182216841215\n",
            "2023-12-13 03:22:52.933515 Epoch 40, Training loss 0.5384333213399178\n",
            "2023-12-13 03:23:08.004044 Epoch 42, Training loss 0.5242434144878113\n",
            "2023-12-13 03:23:22.987278 Epoch 44, Training loss 0.5115977917545816\n",
            "2023-12-13 03:23:37.884464 Epoch 46, Training loss 0.5030347413442414\n",
            "2023-12-13 03:23:53.039865 Epoch 48, Training loss 0.49064891833528373\n",
            "2023-12-13 03:24:08.179658 Epoch 50, Training loss 0.4769599298998399\n",
            "2023-12-13 03:24:23.394232 Epoch 52, Training loss 0.4663222413259825\n",
            "2023-12-13 03:24:38.154971 Epoch 54, Training loss 0.45615825273921223\n",
            "2023-12-13 03:24:53.415358 Epoch 56, Training loss 0.4476283151258358\n",
            "2023-12-13 03:25:08.734313 Epoch 58, Training loss 0.43774524516046465\n",
            "2023-12-13 03:25:23.835861 Epoch 60, Training loss 0.42685456243620723\n",
            "2023-12-13 03:25:39.103906 Epoch 62, Training loss 0.4200469457466329\n",
            "2023-12-13 03:25:54.434491 Epoch 64, Training loss 0.4114018352088529\n",
            "2023-12-13 03:26:09.876883 Epoch 66, Training loss 0.40234651560022217\n",
            "2023-12-13 03:26:24.865669 Epoch 68, Training loss 0.3937670177400532\n",
            "2023-12-13 03:26:40.342142 Epoch 70, Training loss 0.38636091777665144\n",
            "2023-12-13 03:26:55.679588 Epoch 72, Training loss 0.37660068103844585\n",
            "2023-12-13 03:27:11.115802 Epoch 74, Training loss 0.36850716940634387\n",
            "2023-12-13 03:27:26.058417 Epoch 76, Training loss 0.3606508411919926\n",
            "2023-12-13 03:27:41.352683 Epoch 78, Training loss 0.35565992771759297\n",
            "2023-12-13 03:27:56.610371 Epoch 80, Training loss 0.35008951792551857\n",
            "2023-12-13 03:28:11.805747 Epoch 82, Training loss 0.34218972070966097\n",
            "2023-12-13 03:28:27.313935 Epoch 84, Training loss 0.3356606642777006\n",
            "2023-12-13 03:28:42.276732 Epoch 86, Training loss 0.32641108616261777\n",
            "2023-12-13 03:28:57.681623 Epoch 88, Training loss 0.325012778523673\n",
            "2023-12-13 03:29:12.891178 Epoch 90, Training loss 0.31841906560531275\n",
            "2023-12-13 03:29:27.981251 Epoch 92, Training loss 0.30847088451081944\n",
            "2023-12-13 03:29:42.874007 Epoch 94, Training loss 0.30785730079540974\n",
            "2023-12-13 03:29:57.828160 Epoch 96, Training loss 0.2976720210019397\n",
            "2023-12-13 03:30:13.052826 Epoch 98, Training loss 0.292395392667576\n",
            "2023-12-13 03:30:28.374973 Epoch 100, Training loss 0.2877487884792699\n",
            "time: 12min 38s (started: 2023-12-13 03:17:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyBatchNorm, predictionsBatchNorm, expectedLabelsBatchNorm = validate(modelDropout, trainLoader, valLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXrmG1i-mFGk",
        "outputId": "06840c04-5b0d-499d-9ea5-7b8f9659e45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.67\n",
            "Accuracy val: 0.60\n",
            "time: 10 s (started: 2023-12-13 03:30:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisionBatchNorm = precision_score(predictionsBatchNorm, expectedLabelsBatchNorm, average='macro')\n",
        "recallBatchNorm = recall_score(predictionsBatchNorm, expectedLabelsBatchNorm, average='macro')\n",
        "cnfMatrixBatchNorm = confusion_matrix(predictionsBatchNorm, expectedLabelsBatchNorm)\n",
        "print(cnfMatrixBatchNorm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evxicNpCmI0r",
        "outputId": "c36a4311-c035-482f-df3c-03fa600a2a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4272  156  426  124  212   48   49   81  547  208]\n",
            " [ 158 4580   54   58   34   49   48   48  272  566]\n",
            " [ 314   51 3173  418  570  436  271  241  104   55]\n",
            " [ 177   80  398 2996  408 1138  390  313  127  168]\n",
            " [ 120   48  667  398 3568  431  320  502   39   37]\n",
            " [  53   37  344  876  236 3096   98  346   40   39]\n",
            " [  55   99  533  683  476  351 4687  128   73  103]\n",
            " [ 100   59  246  255  401  344   48 4176   43  148]\n",
            " [ 465  203  104   84   49   37   42   39 4480  164]\n",
            " [ 286  687   55  108   46   70   47  126  275 4512]]\n",
            "time: 165 ms (started: 2023-12-13 03:30:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictionsDropout, expectedLabelsDropout, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QY8NTQLm4ui",
        "outputId": "6a9d0a26-cf6b-4411-b102-7aa441a194bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.72      0.69      0.70      6188\n",
            "  automobile       0.77      0.78      0.77      5901\n",
            "        bird       0.53      0.58      0.55      5501\n",
            "         cat       0.49      0.48      0.48      6172\n",
            "        deer       0.60      0.58      0.59      6147\n",
            "         dog       0.51      0.60      0.55      5118\n",
            "        frog       0.78      0.65      0.71      7255\n",
            "       horse       0.70      0.71      0.70      5848\n",
            "        ship       0.74      0.79      0.76      5626\n",
            "       truck       0.75      0.72      0.74      6244\n",
            "\n",
            "    accuracy                           0.66     60000\n",
            "   macro avg       0.66      0.66      0.66     60000\n",
            "weighted avg       0.66      0.66      0.66     60000\n",
            "\n",
            "time: 145 ms (started: 2023-12-13 03:30:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AzRG10iKf28",
        "outputId": "db2f504c-9d95-4640-d0ab-777c00aaceb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 153 ms (started: 2023-12-13 03:30:38 +00:00)\n"
          ]
        }
      ]
    }
  ]
}